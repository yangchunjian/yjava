# 规约总结

## HBase规约
### 使用场景
#### 适用场景
* 海量数据实时查询场景（生产环境基于几十亿数据查询平均耗时小于20ms）

#### 不适用场景
* hbase仅支持通过rowkey查询，不支持不指定rowkey的全表扫描
* hbase不支持关联查询
* hbase不支持统计分析
* hbase不支持事务
* 数据量较小，比如10g以下不建议使用hbase
### 建表
* hbase建表时需要预建region，region个数大于“数据大小/20g”，满足3~5年数据存储需求
* hbase建表时考虑数据清理策略，过期数据优先采用删表的方式清理，特殊情况可以使用TTL

### 设计
* rowkey需要具备唯一性
* rowkey需要避免数据热点问题，可以通过hash、md5等方式增加前缀进行散列
* rowkey通过字典序匹配，设计时需要充分考虑查询条件，必输条件放在非必输条件前，字段之间使用ascii码03分隔
* rowkey需要支持批处理重跑
* rowkey尽量设计成定长，且越短越好，不超过16字节

### 列族
* 将相关性较强的列放在同一个列族下，提高查询性能
* 列族最多2～3个
* 列族、列命名尽量简短

### 数据装载
* hbase支持批量写入，使用bulkload方式
* hbase支持实时写入，使用多线程方式写入


## ElasticSearch规约

### 使用场景
#### 适用场景
* 海量数据实时多维查询
* 全文检索

#### 不适用场景
* es不适用于复杂的统计分析场景
* es不支持事务，不支持关联查询，所以不能作为数据库使用
* es不适用于数据实时生效的场景，es数据写入准实时生效（refresh参数控制，默认1s）
* es不适用于会计核算、反洗钱、外汇监管、客户信息保护等对计算精度及数据安全有特殊要求的场景
* es不适用于精确的TopN统计场景

### 集群选择
* 公共集群
* 自行搭建
* ES云服务

### 索引
* 数据量不超过2T
* 数据条数不超过10亿
* 数据字段不超过50个
* 数据分片大于“数据量/40g”，不超过50个，满足3~5年数据存储需求
* 关闭自动创建索引action.auto_create_index=false

### 字段类型
* 如果没有范围和比较查询，使用keyword类型
* 如果存在范围和比较查询，选择相应的number类型
* 如果存在全文检索，使用text，同时创建keyword类型的字段，用于精确查询
* 预设es索引模板，新建索引时自动匹配模板，避免自动解析导致字段类型不准确的问题（关闭自动创建模版index.mapper.dynamic=false）

### _id设计
* _id具备唯一性
* 对于存在数据更新的场景，需要指定_id生成策略，随着数据量增大，写入时会对_id判重，存在性能问题
* 对于不存在数据更新的场景，无需指定_id，提升写入性能
* 对于批处理场景，_id设计需要支持批处理重跑
* _id不能用于排序，会导致es节点内存告警

### 数据装载
* es支持批量写入，可以基于spark算子或MapReduce框架实现
* es支持实时写入，采用多线程方式写入

### 分页
* 如果业务有跳页需求，需要使用from+size分页方式，仅能查询10000条数据
* 如果查询数据量超过10000条，且无跳页需求，需要使用search_after分页方式

### 压测分析
![img.png](../imgs/all/img.png)

## Hive规约
### 使用场景
#### 适用场景
* 海量数据统计分析场景（生产环境3500+模型平均耗时小于5min）
#### 不适用场景
* hive不适用于OLTP（On-Line Transaction Processing 联机事务处理）场景
* hive不适用于OLAP（On-Line Analytical Processing 联机分析处理）场景
* hive不适用于存在更新和删除的场景
* hive不适用于存在事务的场景
* hive不适用于非结构化数据处理场景
* hive不适用于小数据量和小文件处理场景
### OLTP与OLAP区别

|        | On-Line Transaction Processing | On-Line Analytical Processing |
|--------|--------------------------------|-------------------------------|
| 业务目的   | 处理业务，如订单、合同等                   | 业务支持决策                        |
| 面向对象   | 业务处理人员                         | 分析决策人员                        |
| 主要工作负载 | 增、删、改                          | 查询                            |
| 主要衡量指标 | 事务吞吐量                          | 查询响应速度（QPS）                   |
| 数据库设计  | 3NF或BCNF                       | 星型/雪花模型                       |


### Hive建表
* 应用贴源表（表和表之间大多存在外键依赖被称为低层次表）建议创建外部表
* 应用临时表、中间表等建议创建内部表，并使用parquet（面向列的数据存储格式）方式存储
* 贴源表建议统一使用dtf（树级结构的数据存储方式）文件，解析时使用大数据平台提供的工具

### 数据倾斜
* 参数调优

      hive.map.aggr=true
      hive.groupby.skewindata=true
      hive.merge.mapredfiles=true
* 倾斜数据特殊处理
* 大表和小表关联，尽量使用map join

### HIVE引擎
* 尽量选择spark引擎

## Spark规约

### 使用场景
#### 适用场景
* 海量数据统计分析场景（生产环境3500+模型平均耗时小于5min）
#### 不适用场景
* spark不适用于OLTP（On-Line Transaction Processing 联机事务处理）场景
* spark不适用于OLAP（On-Line Analytical Processing 联机分析处理）场景
* spark不适用于存在更新和删除的场景
* spark不适用于存在事务的场景
* spark不适用于非结构化数据处理场景
* spark不适用于小数据量和小文件处理场景

### SparkSQL开发方式选择
* 简单的数据分析场景可以使用beeline方式
* 复杂的场景建议直接开发，并使用spark-submit进行提交，方便资源灵活调整

### Spark高性能算子
* 使用reduceBykey代替goupBykey
* 使用mapPartions代替map
* 使用foreachPartions代替foreach
* 根据数据量进行适当的重分区，repartion用于增加分区，coalease用于减少分区，filter之后建议使用colease减少分区

## GoldenDB分布式数据库规约

### 字符集
* 规范要求：字符集强制为CHARSET=utf8mb4、字符集校对规则为COLLATE= utf8mb4_bin，必须在表级定义，不允许在字段级定义。
* 控制方式：企业级设计工具生成代码符合规范。源码检查作为强制检查内容，不符合规范则阻断。
* 错误原因：开发、测试环境存在不规范的数据表，使用show create table从开发或测试环境获取建表语句，修改后作为投产内容提交。

#### 参数表设计

|数据维护情况   |表定义方式   |
|---|---|
|参数较少变更，即时生效情况较少  |单节点表，加载内存。<br/>应该直接加载，避免通过SCPRMA加载。<br/>如果有多种查询方式，可以查询按方式加载多份内存。  |
|参数变更较频繁，不会并发修改   |复制表，不加载内存   |
|参数变更频繁，可能并发修改   |单节点表，不加载内存。<br/>（注：需要评审通过）|

### 非参数表设计

| 表类型            |表定义方式   |
|----------------|---|
| 主档表 |原则必须分片。即使数据量很少，但访问量大也必须分片。<br/>必须充分评估业务发展对数据量的影响。（注：如不分片，需要评审通过。）|
| 明细、流水表、登记簿  |必须分片、分区。<br/>一般情况下，在线数据应该控制在3个月之内，超过3个月的应该考虑将历史数据保存到历史数据平台，从历史数据平台查询获取较早的数据。|
| 上传临时   |必须分区。如果数据量大，建议以业务字段进行分片，处理数据时可以按节点并发，性能高。如果要求保证顺序，则只能使用单节点表。|
| 下传临时表   |必须分片、分区。如果没有业务字段可用于分片，则使用批次号进行分片。应该使用技术分片键字段|
| 上/下传共用临时表   |（同上传临时表）|
| 卸数辅助表（_DEL）   |必须要有DEL_DATE字段，所以，任何非_DEL表都不得使用DEL_DATE作为主键，否则无法创建del表。分片规则必须与对应数据表一致。必须分区，一般保留不超过10天。|
| 投产上线时使用的备份表/临时表|必须建立在dcbstmpdb中，分片规则必须与源数据表相同。即如果源数据表为分片表、则备份表/临时表必须分片且分片规则与源数据表相同。如果源数据表为单节点表或复制表、则备份表/临时表为单节点表。|

### 非参数表设计

| 表类型            |表定义方式   |
|----------------|---|
| 主档表 |原则必须分片。即使数据量很少，但访问量大也必须分片。<br/>必须充分评估业务发展对数据量的影响。（注：如不分片，需要评审通过。）|
| 明细、流水表、登记簿  |必须分片、分区。<br/>一般情况下，在线数据应该控制在3个月之内，超过3个月的应该考虑将历史数据保存到历史数据平台，从历史数据平台查询获取较早的数据。|
| 上传临时   |必须分区。如果数据量大，建议以业务字段进行分片，处理数据时可以按节点并发，性能高。如果要求保证顺序，则只能使用单节点表。|
| 下传临时表   |必须分片、分区。如果没有业务字段可用于分片，则使用批次号进行分片。应该使用技术分片键字段|
| 上/下传共用临时表   |（同上传临时表）|
| 卸数辅助表（_DEL）   |必须要有DEL_DATE字段，所以，任何非_DEL表都不得使用DEL_DATE作为主键，否则无法创建del表。分片规则必须与对应数据表一致。必须分区，一般保留不超过10天。|
| 投产上线时使用的备份表/临时表|必须建立在dcbstmpdb中，分片规则必须与源数据表相同。即如果源数据表为分片表、则备份表/临时表必须分片且分片规则与源数据表相同。如果源数据表为单节点表或复制表、则备份表/临时表为单节点表。|

### 分区规则

| 在线时间单位 |在线时间 |分区步长单位  | 分区步长 | 预留分区数 | 备注                            |
|---|---|--|------|-------|-------------------------------|
|D(天)|1--10|D(天)  | 1    | 10    | 新工作完成后，预留分区数会调减为5，进一步减少在线分区总数。 |
|D(天)|11--30 |D(天)  | 5    | 3     | 在线时间尽量按5的倍数设置。                |
|D(天)|31--60 |D(天)  | 10   | 3     | 在线时间尽量按10的倍数设置。60天以上建议按月分区。   |
|D(天)   |61--90 |D(天)  | 15   | 3     | 在线时间尽量按15的倍数设置。90天以上必须按月分区。   |
|M(月)   |1--12|M(月)  | 1    | 3     |                               |
|M(月)   |13--36 |M(月)  | 3    | 3     | 在线时间尽量按3的倍数设置。36个月以上建议按年分区。   |
|M(月)   |37--60|M(月)  | 6    | 3     | 在线时间尽量按6的倍数设置。60个月以上必须按年分区。                              |
|Y(年)   |1--50|Y| 1    | 3     | 建议在线时间最长不超过50年。特殊情况需要审批。                              |


* 分区字段必须为日期(int型)，必须是主键的一个字段。
* 分区表上线时，必须同步增加tblclrcfg配置。（注：有些系统根据此表配置在日终批处理时进行分区清理-删除超过在线时间的分区、新增分区-增加即将使用的分区。）
* 测试环境、生产环境预留分区数应该遵守上表规则，不能按当前日期与投产日期的时间差预留过多分区。

### 命名规范

| 数据项 | 表定义方式 |
|---|---|
| Schema | 数据表使用的Schema为：4位系统名+DB<br/>临时表使用的Schema为：4位系统名+TMP+DB|
| 表名 |对于新增模块建议按规范命名，即:T_2位模块符_表名|
| 索引名|对于新增模块建议按规范命名，即:I_2位模块符_表名_nn(2位索引序号01-99)。<br/>企业设计工具是按规范为索引命名，开发人员需要按规范调整。  |
| 主键名  |PK_表名|
| 字段名  |数据字典名称相同，由词根+‘_’拼接而成，字段名长度不得超过30位。   |


### 字段规范

| 字段|字段定义说明   |
|---|---|
| 银行号字段 |数据表原则上必须包含银行号字段，以支持多法人。<br/>联机批通过报文头的银行号识别法人，联机批使用的上、下传表可以不包含银行号字段。 |
| 时间戳字段 |一般数据表应该包含建立时间戳（新建表时作为倒数第2个字段，建议名称为CRAT_TMTP）、时间戳（新建表时作为最后1个字段，用于保存最后更新时间戳，建议名称为TMTP_TIME）；如果登记簿、流水表、历史表只写入数据，不会更改数据，则可以只保留时间戳字段（用于保存写入时间戳，建议名称为TMTP_TIME）；如果是从数据表移入历史表，则使用建立时间戳（原表数据创建时间，建议名称为CRAT_TMTP）、时间戳（用于保存移入时间戳，建议名称为TMTP_TIME）。上、下传临时表可以不设置时间戳字段。|
| 参数表生效日期、失效日期|参数表原则上应该包含生效日期、失效日期，应该统一命名为TAKE_EFFT_DATE、TAKE_EFFT_EXPI_DATE|
| 备用字段 |数据表原则上不允许使用备用字段。<br/>上、下传临时表，为减少对外围系统的影响，可以设置一个备用字段。   |
| 变长字段 |字段长度大于40，不是主键或索引的字段，且多数情况下不需要赋值或赋值内容长度明显小于字段定义长度，建议使用变长字段。<br/>特别是户名、地址、备注等字段长度较大的字段。   |
| 默认值|字段值不允许为NULL，必须指定默认值。   |



### 分片键及主键设计

|   |规范   | 备注                                                                               |
|---|---|----------------------------------------------------------------------------------|
| 分片键|一般情况下应该使用客户号、机构号、协议号作为分片键来源字段。数据量大，且使用以上字段分片分布明显不均、或不利于批量数据处理，可以使用交易日志号、发起方流水号等作为分片键 | 设计分片键应该考虑以下几点：1.减少联机交易的跨节点事务<br/>2.容易指定分片键值访问，避免全节点遍历<br/>3.考虑数据分布，避免倾斜<br/>4.要兼顾联机交易、批量交易的使用方式 |
| 主键 |主键必须唯一（全局唯一）<br/>原则上主键应该包括分片键来源字段   | 以客户号、机构号作为分片键，为避免客户号合并、机构撤并可能导致修改主键，主键可以不包括客户号、机构号，但必须保证全局唯一。                                                                                 |
| 转换表|如果数据表是分区表，则基于此数据表生成的转换表也应该是分区表，分区步长、在线时间应该与数据表一致。   |应该关注设计工具的配置项：无记录不查询标识，一般情况应该选择Y，避免全表遍历；如果设置为N，必须通过评审确认。                                                                                  |

### 索引设计

|   |  规范 | 备注  |
|---|---|---|
| 基本规范  |原则上索引不超过5个<br/>原则上索引包含的字段不超过5个  |   |
| 索引字段定义|一般情况下应该将区分度强的字段放在索引的前面|   |
| 索引字段使用|指定排序或分组时，应该按索引字段的顺序，从左到右顺序使用   |   |

### 表、索引、字段变更

|变更内容   |规范   |备注   |
|---|---|---|
|删除表   |原则上不允许删除表   |必须删除，应该改名后移入DCBSTMPDB，便于异常回退处理。确实不再使用，由自动清理工具定期清理，一般在线一个月。   |
|修改表   |原则上不允许修改表，如果必须修改，按先删除、再增加处理   |需要考虑数据迁移方法及时间点。数据量大使用loadserver导出、导入，需要考虑数据的准确性及对业务连续性影响   |
|索引变更   |原则上不允许直接修改索引，应该先增加新索引、再删除旧索引   |需要考虑数据量对新增索引耗时对投产上线时间的影响，如果影响较大，应该提前部署   |
|主键变更   |原则上不允许修改主键   |如果必须修改，按修改表处理   |
|分片键变更   |原则上不允许修改分片键   |如果必须修改，按修改表处理。如果此表包含转换表，则必须同步更新转换表   |
|字段变更   |原则上不允许删除、修改字段，只允许增加字段。<br/>非上、下传临时表，新增字段必须加在表字段的最后，脚本中不允许出现before、after；上、下传临时表，新增字段加在4个标准字段之前 |如果存量数据需要的迁移，必须考虑数据量投产上线时间的影响，一般情况下应该在蓝、绿部署之后（即服务正常启动后）执行数据迁移。|
