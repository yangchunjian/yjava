# 规约总结

## HBase规约
### 使用场景
#### 适用场景
* 海量数据实时查询场景（生产环境基于几十亿数据查询平均耗时小于20ms）

#### 不适用场景
* hbase仅支持通过rowkey查询，不支持不指定rowkey的全表扫描
* hbase不支持关联查询
* hbase不支持统计分析
* hbase不支持事务
* 数据量较小，比如10g以下不建议使用hbase
### 建表
* hbase建表时需要预建region，region个数大于“数据大小/20g”，满足3~5年数据存储需求
* hbase建表时考虑数据清理策略，过期数据优先采用删表的方式清理，特殊情况可以使用TTL

### 设计
* rowkey需要具备唯一性
* rowkey需要避免数据热点问题，可以通过hash、md5等方式增加前缀进行散列
* rowkey通过字典序匹配，设计时需要充分考虑查询条件，必输条件放在非必输条件前，字段之间使用ascii码03分隔
* rowkey需要支持批处理重跑
* rowkey尽量设计成定长，且越短越好，不超过16字节

### 列族
* 将相关性较强的列放在同一个列族下，提高查询性能
* 列族最多2～3个
* 列族、列命名尽量简短

### 数据装载
* hbase支持批量写入，使用bulkload方式
* hbase支持实时写入，使用多线程方式写入


## ElasticSearch规约

### 使用场景
#### 适用场景
* 海量数据实时多维查询
* 全文检索

#### 不适用场景
* es不适用于复杂的统计分析场景
* es不支持事务，不支持关联查询，所以不能作为数据库使用
* es不适用于数据实时生效的场景，es数据写入准实时生效（refresh参数控制，默认1s）
* es不适用于会计核算、反洗钱、外汇监管、客户信息保护等对计算精度及数据安全有特殊要求的场景
* es不适用于精确的TopN统计场景

### 集群选择
* 公共集群
* 自行搭建
* ES云服务

### 索引
* 数据量不超过2T
* 数据条数不超过10亿
* 数据字段不超过50个
* 数据分片大于“数据量/40g”，不超过50个，满足3~5年数据存储需求
* 关闭自动创建索引action.auto_create_index=false

### 字段类型
* 如果没有范围和比较查询，使用keyword类型
* 如果存在范围和比较查询，选择相应的number类型
* 如果存在全文检索，使用text，同时创建keyword类型的字段，用于精确查询
* 预设es索引模板，新建索引时自动匹配模板，避免自动解析导致字段类型不准确的问题（关闭自动创建模版index.mapper.dynamic=false）

### _id设计
* _id具备唯一性
* 对于存在数据更新的场景，需要指定_id生成策略，随着数据量增大，写入时会对_id判重，存在性能问题
* 对于不存在数据更新的场景，无需指定_id，提升写入性能
* 对于批处理场景，_id设计需要支持批处理重跑
* _id不能用于排序，会导致es节点内存告警

### 数据装载
* es支持批量写入，可以基于spark算子或MapReduce框架实现
* es支持实时写入，采用多线程方式写入

### 分页
* 如果业务有跳页需求，需要使用from+size分页方式，仅能查询10000条数据
* 如果查询数据量超过10000条，且无跳页需求，需要使用search_after分页方式

### 压测分析
![img.png](../imgs/all/img.png)

## Hive规约
### 使用场景
#### 适用场景
* 海量数据统计分析场景（生产环境3500+模型平均耗时小于5min）
#### 不适用场景
* hive不适用于OLTP（On-Line Transaction Processing 联机事务处理）场景
* hive不适用于OLAP（On-Line Analytical Processing 联机分析处理）场景
* hive不适用于存在更新和删除的场景
* hive不适用于存在事务的场景
* hive不适用于非结构化数据处理场景
* hive不适用于小数据量和小文件处理场景
### OLTP与OLAP区别

|        | On-Line Transaction Processing | On-Line Analytical Processing |
|--------|--------------------------------|-------------------------------|
| 业务目的   | 处理业务，如订单、合同等                   | 业务支持决策                        |
| 面向对象   | 业务处理人员                         | 分析决策人员                        |
| 主要工作负载 | 增、删、改                          | 查询                            |
| 主要衡量指标 | 事务吞吐量                          | 查询响应速度（QPS）                   |
| 数据库设计  | 3NF或BCNF                       | 星型/雪花模型                       |


### Hive建表
* 应用贴源表（表和表之间大多存在外键依赖被称为低层次表）建议创建外部表
* 应用临时表、中间表等建议创建内部表，并使用parquet（面向列的数据存储格式）方式存储
* 贴源表建议统一使用dtf（树级结构的数据存储方式）文件，解析时使用大数据平台提供的工具

### 数据倾斜
* 参数调优

      hive.map.aggr=true
      hive.groupby.skewindata=true
      hive.merge.mapredfiles=true
* 倾斜数据特殊处理
* 大表和小表关联，尽量使用map join

### HIVE引擎
* 尽量选择spark引擎

## Spark规约

### 使用场景
#### 适用场景
* 海量数据统计分析场景（生产环境3500+模型平均耗时小于5min）
#### 不适用场景
* spark不适用于OLTP（On-Line Transaction Processing 联机事务处理）场景
* spark不适用于OLAP（On-Line Analytical Processing 联机分析处理）场景
* spark不适用于存在更新和删除的场景
* spark不适用于存在事务的场景
* spark不适用于非结构化数据处理场景
* spark不适用于小数据量和小文件处理场景

### SparkSQL开发方式选择
* 简单的数据分析场景可以使用beeline方式
* 复杂的场景建议直接开发，并使用spark-submit进行提交，方便资源灵活调整

### Spark高性能算子
* 使用reduceBykey代替goupBykey
* 使用mapPartions代替map
* 使用foreachPartions代替foreach
* 根据数据量进行适当的重分区，repartion用于增加分区，coalease用于减少分区，filter之后建议使用colease减少分区
